# Program: BLE_Calib_Terminal.py
# Purpose: Guided calibration tool for BLE iBeacon proximity detection.
#          Collects RSSI data at known distances, calculates optimal parameters,
#          and exports them for use in the main door opener system.
#          Terminal-based version without GUI for maximum stability.
# Author: Dr. Ralf Korell / CircuIT
# Creation Date: August 19, 2025
# Modified: August 19, 2025 - Initial terminal-only implementation.
# Corrected: August 19, 2025, 16:45 UTC - Fixed BleakScanner initialization (AttributeError) and implemented
#            continuous CSV logging after each measurement phase to prevent data loss on crash.
# Corrected: August 19, 2025, 17:00 UTC - Fixed BleakScanner.is_scanning AttributeError and ensured robust CSV/JSON export.
# Corrected: August 19, 2025, 17:15 UTC - Ensured CSV and JSON files are actually written to disk by awaiting async calls and flushing.
# Corrected: August 19, 2025, 17:30 UTC - Verified file writing logic and data consistency for CSV and JSON export.

import asyncio
import time
import os
import csv
import json
import logging
import statistics # For standard deviation
import numpy as np # For linear regression
import math # For log10

# BLE Imports
from bleak import BleakScanner
import struct

# --- Logging Konfiguration für den Kalibrator ---
# Log-Meldungen werden in die Konsole und in eine Datei geschrieben.
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - BLE_CALIB - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(), # Ausgabe auf die Konsole
        logging.FileHandler("ble_calibrator.log") # Ausgabe in eine Logdatei
    ]
)

# --- Globale Variablen für den BLE Scan ---
# Stores the latest RSSI for each targeted MAC address
# { "MAC_ADDRESS": { "name": "Beacon Name", "latest_rssi": int, "last_seen_time": float } }
beacon_last_seen_data = {} 
current_calibration_data_buffer = [] # Buffer for data collected during one measurement phase

# --- KONFIGURATION ---

# BLE iBeacon Konfiguration
TARGET_IBEACON_UUID = "E2C56DB5-DFFB-48D2-B060-D0F5A71096E0" # UUID ist für alle Minew Beacons identisch
CALIBRATED_MEASURED_POWER_DEFAULT = -77 # Kalibrierter Measured Power (Tx Power @ 1m vom Beacon)
PATH_LOSS_EXPONENT_DEFAULT = 2.5 # Pfadverlust-Exponent (N): Typischerweise 2.0 für freie Sicht, 2.5-4.0 für Innenräume.

# Proximity und Debouncing Konfiguration (relevant für _run_ble_scan_background_task)
ABSENCE_DETECTION_TIME = 10 # Sekunden: Zeit, die der Beacon nicht erkannt werden darf, um aus der Liste zu fallen

# Konfigurationsdatei für erlaubte Nutzer und deren Beacons (für allowed_majors)
ALLOWED_USERS_CONFIG = "Erlaubte_Nutzer.conf"

# Kalibrierungsspezifische Konfiguration
CALIBRATION_DISTANCES = [
    # Annäherung 1: Start bei 5m, engere Schritte im Nahbereich
    5.0, 4.5, 4.0, 3.5, 3.0, 2.5, 2.0, 1.75, 1.5, 1.25, 1.0, 0.75, 0.5, 0.25,
    # Entfernung 1: Rückweg
    0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0,
    # Annäherung 2: Start bei 4m, engere Schritte im Nahbereich
    4.0, 3.5, 3.0, 2.5, 2.0, 1.75, 1.5, 1.25, 1.0, 0.75, 0.5, 0.25
]
PRE_MEASUREMENT_DELAY_SEC = 5 # Sekunden Countdown vor jeder Messphase
MEASUREMENT_DURATION_SEC = 15 # Sekunden Dauer der Datensammlung pro Abstand
BLE_SCAN_INTERVAL_SEC = 1.0 # Sekunden Intervall für den BLE-Scan (für Hintergrund-Scan)

# --- Hilfsfunktionen ---

def cleanup_gpio():
    """Räumt die GPIO-Einstellungen auf. (Platzhalter, da nicht direkt verwendet)"""
    try:
        import RPi.GPIO as GPIO
        if GPIO.getmode() is not None:
            GPIO.cleanup()
            logging.info("GPIO aufgeräumt.")
    except ImportError:
        logging.warning("RPi.GPIO nicht importierbar, überspringe GPIO-Cleanup.")

def bytes_to_uuid(b):
    return f"{b[0:4].hex()}-{b[4:6].hex()}-{b[6:8].hex()}-{b[8:10].hex()}-{b[10:16].hex()}".upper()

def estimate_distance(rssi, measured_power, n):
    if rssi == 0:
        return -1.0
    return 10 ** ((measured_power - rssi) / (10 * n))

def read_allowed_users_config():
    """
    Liest die Konfigurationsdatei für erlaubte Nutzer und deren Beacons ein.
    Format: Name;wahr/falsch;Major1;Major2;Major3
    """
    allowed_users = {}
    script_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(script_dir, ALLOWED_USERS_CONFIG)

    if os.path.exists(config_path):
        try:
            with open(config_path, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'): # Kommentare und leere Zeilen ignorieren
                        continue
                    
                    parts = line.split(';')
                    if len(parts) < 2:
                        logging.warning(f"Ungültige Zeile in '{ALLOWED_USERS_CONFIG}': '{line}'. Erwarte mindestens Name;Status.")
                        continue
                    
                    name = parts[0].strip()
                    status_str = parts[1].strip().lower()
                    allowed = (status_str == 'wahr')
                    
                    beacon_majors = []
                    # Lese Major-Werte ab dem dritten Feld
                    for i in range(2, len(parts)):
                        major_str = parts[i].strip()
                        if major_str:
                            try:
                                beacon_majors.append(int(major_str))
                            except ValueError:
                                logging.warning(f"Ungültiger Major-Wert '{major_str}' für Nutzer '{name}' in '{ALLOWED_USERS_CONFIG}'. Ignoriere.")
                    
                    allowed_users[name] = {
                        'allowed': allowed,
                        'beacon_majors': beacon_majors
                    }
        except Exception as e:
            logging.error(f"Fehler beim Lesen von '{ALLOWED_USERS_CONFIG}': {e}")
    return allowed_users

# --- BLE Scan Hintergrund-Task ---
# NEU: detection_callback ist nun eine eigenständige Funktion, die direkt an BleakScanner übergeben wird
def bleak_detection_callback(device, advertisement_data):
    rssi_val = advertisement_data.rssi
    
    if 0x004C in advertisement_data.manufacturer_data:
        mfg_data = advertisement_data.manufacturer_data[0x004C]
        
        if len(mfg_data) >= 23 and mfg_data[0] == 0x02 and mfg_data[1] == 0x15:
            try:
                uuid_bytes, major_val, minor_val, measured_power = struct.unpack_from(">16sHHb", mfg_data, 2)
            except struct.error:
                return

            uuid_str = bytes_to_uuid(uuid_bytes)

            # Hole die erlaubten Major-Werte (muss hier global oder über Argumente verfügbar sein)
            # Für diese Funktion ist es am einfachsten, sie als globales Attribut zu behandeln,
            # da sie von bleak aufgerufen wird.
            global allowed_majors_for_scan # Muss in main_calibration_workflow gesetzt werden
            
            if uuid_str == TARGET_IBEACON_UUID and major_val in allowed_majors_for_scan:
                distance = estimate_distance(rssi_val, CALIBRATED_MEASURED_POWER_DEFAULT, PATH_LOSS_EXPONENT_DEFAULT)
                
                beacon_info = {
                    'timestamp': time.time(),
                    'mac': device.address,
                    'major': major_val,
                    'minor': minor_val,
                    'rssi': rssi_val,
                    'distance': distance
                }
                beacon_last_seen_data[device.address] = beacon_info

                # Wenn Kalibrierung läuft, Daten zum Puffer hinzufügen
                # Prüfe, ob der Haupt-Kalibrierungs-Workflow-Task aktiv ist
                # Dies ist eine Heuristik, um zu vermeiden, dass Daten gesammelt werden,
                # bevor der Workflow gestartet wurde oder nachdem er beendet ist.
                current_task = asyncio.current_task()
                if current_task and current_task.get_name() == "calibration_workflow_task":
                    current_calibration_data_buffer.append(beacon_info)
                
# NEU: _run_ble_scan_background_task nimmt den Scanner direkt entgegen
async def _run_ble_scan_background_task(scanner_instance):
    """
    Führt den BLE-Scan kontinuierlich im Hintergrund aus und aktualisiert beacon_last_seen_data.
    """
    logging.info("BLE Scan Hintergrund-Task gestartet.")
    
    # Der detection_callback wird nun beim Instanziieren des Scanners übergeben.
    # Hier wird nur der Loop für den Scanner verwaltet.
    try:
        while True: 
            current_time = time.time()
            addresses_to_remove = [
                addr for addr, data in beacon_last_seen_data.items()
                if current_time - data['timestamp'] > ABSENCE_DETECTION_TIME
            ]
            for addr in addresses_to_remove:
                del beacon_last_seen_data[addr]
                logging.debug(f"Beacon {addr} aus Liste entfernt (zu alt oder zu weit weg).")

            await asyncio.sleep(BLE_SCAN_INTERVAL_SEC)
    except asyncio.CancelledError:
        logging.info("BLE Scan Hintergrund-Task beendet.")
    finally:
        # Der Scanner wird im main_calibration_workflow gestartet und gestoppt.
        # Hier nur sicherstellen, dass der Task sauber beendet wird.
        pass


# --- Parameterberechnung und Export ---
def _calculate_and_export_parameters(all_calibration_data):
    logging.info("Starte Parameterberechnung und Export.")
    
    # Group data by unique beacon (MAC, Major, Minor)
    grouped_beacons_data = {}
    for data_point in all_calibration_data:
        beacon_id = (data_point['Beacon_Address'], data_point['Beacon_Major'], data_point['Beacon_Minor'])
        if beacon_id not in grouped_beacons_data:
            grouped_beacons_data[beacon_id] = []
        grouped_beacons_data[beacon_id].append(data_point)

    calibrated_beacons = []
    for (mac, major, minor), data_points in grouped_beacons_data.items():
        rssi_values = [dp['RSSI_Value'] for dp in data_points]
        actual_distances = [dp['Actual_Distance_Provided'] for dp in data_points]

        if len(rssi_values) < 2:
            logging.warning(f"Nicht genug Datenpunkte für Beacon {mac}/{major}/{minor} zur Kalibrierung. Überspringe.")
            continue

        # Perform linear regression to find optimal measured_power and path_loss_exponent
        # Formula: RSSI = measured_power - 10 * n * log10(distance)
        # Rearrange to linear form: RSSI = A + B * log10(distance)
        # Where A = measured_power, B = -10 * n
        # So, n = -B / 10
        
        # Filter out distances <= 0 to avoid log(0)
        valid_data = [(r, d) for r, d in zip(rssi_values, actual_distances) if d > 0]
        if not valid_data:
            logging.warning(f"Keine gültigen Datenpunkte für Beacon {mac}/{major}/{minor} (Abstand <= 0). Überspringe.")
            continue

        rssi_for_reg = [item[0] for item in valid_data]
        log_distances = [10 * math.log10(item[1]) for item in valid_data] # Multiply by 10 for direct regression on -10n

        try:
            # Use numpy for linear regression
            # x = log_distances, y = rssi_for_reg
            A = np.vstack([log_distances, np.ones(len(log_distances))]).T
            m, c = np.linalg.lstsq(A, rssi_for_reg, rcond=None)[0]

            # m is -10 * n, c is measured_power
            calibrated_n = -m / 10
            calibrated_mp = c

            logging.info(f"Kalibrierte Parameter für Beacon {mac}/{major}/{minor}: Measured Power={calibrated_mp:.2f}, Path Loss Exponent={calibrated_n:.2f}")

            calibrated_beacons.append({
                "major": major,
                "minor": minor,
                "mac_address": mac,
                "calibrated_measured_power": round(calibrated_mp, 2),
                "path_loss_exponent": round(calibrated_n, 2)
            })

        except Exception as e:
            logging.error(f"Fehler bei der Regression für Beacon {mac}/{major}/{minor}: {e}")

    # Export to JSON
    output_data = {
        "beacon_uuid": TARGET_IBEACON_UUID,
        "calibrated_beacons": calibrated_beacons,
        "global_defaults": {
            "calibrated_measured_power": CALIBRATED_MEASURED_POWER_DEFAULT,
            "path_loss_exponent": PATH_LOSS_EXPONENT_DEFAULT
        }
    }
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    json_output_path = os.path.join(script_dir, "beacon_calibration_params.json")
    
    try:
        with open(json_output_path, 'w') as f:
            json.dump(output_data, f, indent=4)
            f.flush() # NEU: Daten auf die Festplatte schreiben
            os.fsync(f.fileno()) # NEU: Sicherstellen, dass der OS-Puffer geleert wird
        logging.info(f"Kalibrierte Parameter erfolgreich nach '{json_output_path}' exportiert.")
    except Exception as e:
        logging.error(f"Fehler beim Export der Kalibrierungs-JSON: {e}")

# NEU: Funktion zum fortlaufenden Speichern der Rohdaten in CSV
async def _append_raw_data_to_csv(data_points, csv_output_path):
    """
    Fügt die gesammelten Rohdaten zu einer CSV-Datei hinzu.
    Erstellt die Datei mit Header, falls sie noch nicht existiert.
    """
    if not data_points:
        return

    file_exists = os.path.exists(csv_output_path)
    
    try:
        with open(csv_output_path, 'a', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['Timestamp', 'Beacon_Address', 'Beacon_Major', 'Beacon_Minor', 
                          'RSSI_Value', 'Calculated_Distance', 'Actual_Distance_Provided', 
                          'RSSI_StdDev_During_Measurement', 'Num_Packets_Received_During_Measurement'] # Explizite Reihenfolge
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            if not file_exists:
                writer.writeheader()
                logging.info(f"CSV-Datei '{csv_output_path}' erstellt und Header geschrieben.")
            
            writer.writerows(data_points)
            csvfile.flush() # NEU: Daten auf die Festplatte schreiben
            os.fsync(csvfile.fileno()) # NEU: Sicherstellen, dass der OS-Puffer geleert wird
            logging.info(f"Rohdaten von {len(data_points)} Einträgen erfolgreich an '{csv_output_path}' angehängt.")
    except Exception as e:
        logging.error(f"Fehler beim Anhängen der Rohdaten an CSV '{csv_output_path}': {e}")


# --- Haupt-Kalibrierungs-Workflow (Terminal-basiert) ---
# NEU: Globale Variable für erlaubte Major-Werte, zugänglich für bleak_detection_callback
allowed_majors_for_scan = set()

async def main_calibration_workflow():
    global allowed_majors_for_scan # Muss hier als global deklariert werden, um sie zu setzen

    print("\n" * 2) # Leerzeilen für bessere Sichtbarkeit
    print("=" * 60)
    print("      STARTE BLE BEACON KALIBRIERUNG (TERMINAL-MODUS)")
    print("=" * 60)
    print("\n")

    # Initialisiere allowed_majors_for_scan
    allowed_users_data = read_allowed_users_config()
    for user_data in allowed_users_data.values():
        if user_data['allowed']:
            allowed_majors_for_scan.update(user_data['beacon_majors'])
    logging.info(f"Erlaubte Major-Werte für BLE-Filterung: {allowed_majors_for_scan}")
    
    if not allowed_majors_for_scan:
        logging.error("Keine erlaubten Major-Werte in 'Erlaubte_Nutzer.conf' gefunden. Bitte konfigurieren Sie mindestens einen Beacon.")
        print("\n" * 2)
        print("FEHLER: Keine Beacons zur Kalibrierung konfiguriert. Bitte 'Erlaubte_Nutzer.conf' prüfen.")
        print("\n" * 2)
        return

    all_calibration_data = [] # List to store all collected data points
    
    # NEU: BleakScanner korrekt initialisieren
    scanner = BleakScanner(bleak_detection_callback)
    
    # Start the BLE scanner
    await scanner.start()
    logging.info("BLE Scanner gestartet.")

    # Start the background scan task (now only manages cleanup of beacon_last_seen_data)
    scan_task = asyncio.create_task(_run_ble_scan_background_task(scanner), name="background_scan_task")

    # NEU: Pfad für die CSV-Rohdaten festlegen
    csv_output_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), f"ble_calibration_data_{int(time.time())}.csv")

    try:
        # Set task name for current workflow to allow detection_callback to know if calibration is active
        asyncio.current_task().set_name("calibration_workflow_task")

        print("\n" * 2)
        print("--- KALIBRIERUNG STARTET ---")
        print("Folgen Sie den Anweisungen und bewegen Sie den Beacon entsprechend.")
        print("Das Programm wartet automatisch zwischen den Schritten.")
        print("\n" * 2)

        for i, target_distance in enumerate(CALIBRATION_DISTANCES):
            print("=" * 60)
            print(f"SCHRITT {i+1}/{len(CALIBRATION_DISTANCES)}")
            print(f"PLATZIEREN SIE DEN BEACON AUF: {target_distance:.1f} METER ENTFERNUNG ZUM RASPBERRY PI")
            print("=" * 60)
            print("\n")
            logging.info(f"Nächster Messpunkt: {target_distance:.1f} Meter.")
            
            # Countdown phase
            for count in range(PRE_MEASUREMENT_DELAY_SEC, 0, -1):
                print(f"Bereit in... {count} Sekunden")
                await asyncio.sleep(1)
            print("LOS!\n")

            # Measurement phase
            print(f"Messe bei {target_distance:.1f} Meter für {MEASUREMENT_DURATION_SEC} Sekunden.")
            print("Bewegen Sie den Beacon leicht, um verschiedene Signalpfade zu erfassen.")
            logging.info(f"Starte Messung bei {target_distance:.1f} Meter für {MEASUREMENT_DURATION_SEC} Sekunden.")
            
            current_calibration_data_buffer.clear() # Clear buffer for this measurement
            measurement_start_time = time.time()
            
            # Wait for measurement duration, allowing background scan to fill buffer
            while time.time() - measurement_start_time < MEASUREMENT_DURATION_SEC:
                await asyncio.sleep(0.1) # Small sleep to yield control

            # Process collected data for this phase
            if current_calibration_data_buffer:
                # Group data by beacon (MAC, Major, Minor)
                grouped_data = {}
                for beacon_info in current_calibration_data_buffer:
                    beacon_id = (beacon_info['mac'], beacon_info['major'], beacon_info['minor'])
                    if beacon_id not in grouped_data:
                        grouped_data[beacon_id] = []
                    grouped_data[beacon_id].append(beacon_info['rssi'])
                
                processed_phase_data = [] # Data for this specific phase to be written to CSV
                for (mac, major, minor), rssi_values in grouped_data.items():
                    if len(rssi_values) > 1: # Need at least 2 points for std dev
                        rssi_std_dev = statistics.stdev(rssi_values)
                    else:
                        rssi_std_dev = 0.0 # No std dev for single or no value

                    # Average RSSI for this measurement phase
                    avg_rssi = statistics.mean(rssi_values) if rssi_values else 0
                    avg_distance = estimate_distance(avg_rssi, CALIBRATED_MEASURED_POWER_DEFAULT, PATH_LOSS_EXPONENT_DEFAULT)

                    data_point_entry = {
                        'Timestamp': time.time(),
                        'Beacon_Address': mac,
                        'Beacon_Major': major,
                        'Beacon_Minor': minor,
                        'RSSI_Value': avg_rssi, # Store average RSSI for this measurement phase
                        'Calculated_Distance': avg_distance,
                        'Actual_Distance_Provided': target_distance,
                        'RSSI_StdDev_During_Measurement': rssi_std_dev,
                        'Num_Packets_Received_During_Measurement': len(rssi_values)
                    }
                    all_calibration_data.append(data_point_entry) # Add to overall list for final JSON
                    processed_phase_data.append(data_point_entry) # Add to list for this phase's CSV write

                    logging.info(f"Gesammelte Daten für {mac}/{major}/{minor} bei {target_distance:.1f}m: Avg RSSI={avg_rssi:.2f}, StdDev={rssi_std_dev:.2f}, Pakete={len(rssi_values)}")
                
                # NEU: Rohdaten nach jeder Messphase in CSV schreiben
                await _append_raw_data_to_csv(processed_phase_data, csv_output_path)

            else:
                logging.warning(f"Keine Beacon-Daten bei {target_distance:.1f}m gesammelt. Beacon nicht in Reichweite?")
            
            print("\n")
            print("-" * 60)
            print("MESSUNG ABGESCHLOSSEN. BEREIT FÜR NÄCHSTEN SCHRITT.")
            print("-" * 60)
            print("\n" * 2)

        # Calibration finished successfully
        print("=" * 60)
        print("      KALIBRIERUNG ABGESCHLOSSEN!")
        print("      Berechne und exportiere Parameter...")
        print("=" * 60)
        logging.info("Geführte BLE Kalibrierung erfolgreich abgeschlossen.")
        
        _calculate_and_export_parameters(all_calibration_data)

    except asyncio.CancelledError:
        logging.info("Kalibrierungs-Workflow abgebrochen.")
        print("\n" * 2)
        print("--- KALIBRIERUNG ABGEBROCHEN ---")
        print("\n" * 2)
    except Exception as e:
        logging.critical(f"Ein kritischer Fehler ist aufgetreten: {e}", exc_info=True)
        print("\n" * 2)
        print("=" * 60)
        print("      FEHLER WÄHREND DER KALIBRIERUNG!")
        print(f"      Details im Log: {e}")
        print("=" * 60)
        print("\n" * 2)
    finally:
        # Ensure background scan task is cancelled and awaited
        if scan_task:
            scan_task.cancel()
            try:
                await scan_task
            except asyncio.CancelledError:
                pass
        # Scanner muss hier gestoppt werden, da er im main_calibration_workflow gestartet wurde.
        # Der Aufruf von stop() ist idempotent und kann sicher mehrfach aufgerufen werden.
        await scanner.stop()
        logging.info("BLE Scanner gestoppt.")
        logging.info("Alle Tasks beendet. Programmende.")
        cleanup_gpio()


# --- Hauptausführung ---
if __name__ == "__main__":
    # Ensure multiprocessing is set to spawn for compatibility
    # This must be done at the very beginning of the main process
    import multiprocessing
    multiprocessing.set_start_method('spawn', force=True)

    try:
        asyncio.run(main_calibration_workflow())
    except KeyboardInterrupt:
        logging.info("Programm beendet durch Benutzer (Strg+C).")
    except Exception as e:
        logging.critical(f"Ein kritischer Fehler ist aufgetreten: {e}", exc_info=True)