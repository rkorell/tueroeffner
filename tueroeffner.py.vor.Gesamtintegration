# Program: tueroeffner.py
# Purpose: Gesichtserkennungssystem mit Liveness Detection und Relais-Steuerung.
#          Erkennt bekannte Personen, prüft auf Lebendigkeit und schaltet ein Relais,
#          wenn die Person in der Konfigurationsdatei als "wahr" markiert ist.
# Author: Dr. Ralf Korell
# Creation Date: July 25, 2025

import face_recognition
import RPi.GPIO as GPIO
import time
import pickle
import numpy as np
import cv2
import atexit
import os

# Picamera2 Import
from picamera2 import Picamera2
from libcamera import controls # Für Autofokus-Modi

# --- Konfiguration ---
ENCODINGS_FILE = "encodings.pkl" # Pfad zur Datei mit den trainierten Gesichts-Encodings
RELAY_PIN = 23 # NEU: GPIO-Pin, an den das Relais angeschlossen ist (BCM-Modus)
RELAY_ACTIVATION_TIME = 2 # Sekunden, wie lange das Relais aktiv bleiben soll
CAMERA_RESOLUTION = (640, 480) # Auflösung der Kamera. Kleinere Auflösung = schnellere Verarbeitung
FRAME_RESIZE_FACTOR = 0.25 # Faktor zur Skalierung des Frames für die Gesichtserkennung (z.B. 0.25 = 1/4 Größe)

# Liveness Detection Parameter
LIVENESS_CONFIRM_COUNT = 5 # Anzahl der aufeinanderfolgenden Frames mit Bewegung, um Liveness zu bestätigen
LIVENESS_PIXEL_DIFF_THRESHOLD = 5000 # Schwellenwert für die Summe der absoluten Pixelunterschiede (SAD)
                                      # Höherer Wert = weniger empfindlich. Muss eventuell angepasst werden!
MIN_DETECTION_INTERVAL = 5 # Sekunden, um eine erneute Auslösung nach erfolgreicher Erkennung zu verhindern

# Debug-Parameter
CAMERA_DEBUG = True # Setze auf True, um das Kamerabild anzuzeigen, False sonst

# Konfigurationsdatei für erlaubte Nutzer
ALLOWED_USERS_CONFIG = "Erlaubte_Nutzer.conf"

# Autofokus Konfigurationsparameter
SET_AUTOFOCUS = True # Setze auf True für Autofokus, False für festen Fokus

# --- Hilfsfunktionen für Konfigurationsdatei ---
def read_allowed_users_config():
    """Liest die Konfigurationsdatei für erlaubte Nutzer ein."""
    allowed_users = {}
    if os.path.exists(ALLOWED_USERS_CONFIG):
        try:
            with open(ALLOWED_USERS_CONFIG, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and ';' in line:
                        name, status = line.split(';', 1)
                        allowed_users[name.strip()] = status.strip().lower()
        except Exception as e:
            print(f"Warnung: Fehler beim Lesen von '{ALLOWED_USERS_CONFIG}': {e}")
    return allowed_users

# --- GPIO Initialisierung ---
def setup_gpio():
    """Initialisiert den GPIO-Pin für das Relais."""
    GPIO.setwarnings(False) # Warnungen von RPi.GPIO unterdrücken
    GPIO.setmode(GPIO.BCM) # Verwende BCM-Pin-Nummerierung (nicht BOARD)
    GPIO.setup(RELAY_PIN, GPIO.OUT)
    GPIO.output(RELAY_PIN, GPIO.LOW) # Relais initial ausschalten (oder HIGH, je nach Relais-Modul)
    print(f"GPIO Pin {RELAY_PIN} als Ausgang konfiguriert und initial deaktiviert.")

def cleanup_gpio():
    """Räumt die GPIO-Einstellungen auf."""
    if GPIO.getmode() is not None:
        GPIO.cleanup()
        print("GPIO aufgeräumt.")

# Registriere die cleanup_gpio Funktion, die beim Beenden des Programms aufgerufen wird
atexit.register(cleanup_gpio)

# --- Hauptprogramm ---
def run_face_recognition_system():
    setup_gpio()

    try:
        # Lade die bekannten Gesichts-Encodings und Namen
        print(f"Lade Gesichts-Encodings von '{ENCODINGS_FILE}'...")
        try:
            with open(ENCODINGS_FILE, 'rb') as f:
                known_face_encodings, known_face_names = pickle.load(f)
            print(f"{len(known_face_encodings)} Encodings von {len(set(known_face_names))} Personen geladen.")
        except FileNotFoundError:
            print(f"Fehler: Die Datei '{ENCODINGS_FILE}' wurde nicht gefunden. Bitte führen Sie zuerst das Trainingsskript aus.")
            return
        except Exception as e:
            print(f"Fehler beim Laden der Encodings: {e}")
            return

        # Initialisiere Picamera2
        picam2 = Picamera2()

        # Konfiguriere die Kamera
        camera_config = picam2.create_video_configuration(main={"size": CAMERA_RESOLUTION, "format": "RGB888"})
        picam2.configure(camera_config)

        # Starte die Kamera
        picam2.start()
        time.sleep(1) # Kurze Pause, damit die Kamera bereit ist

        # Autofokus konfigurieren und starten, falls aktiviert
        if SET_AUTOFOCUS:
            picam2.set_controls({"AfMode": controls.AfMode.Continuous}) # Oder 2, falls controls.AfMode nicht funktioniert
            print("Kontinuierlicher Autofokus aktiviert.")
        else:
            picam2.set_controls({"AfMode": controls.AfMode.Manual}) # Oder 0
            # Optional: picam2.set_controls({"LensPosition": 1.0}) # Beispiel: Manuellen Fokus auf 1.0 setzen
            print("Autofokus deaktiviert.")


        # Variablen für Liveness Detection und Erkennungsstatus
        last_face_frame_data = None
        liveness_counter = 0
        last_recognition_time = 0

        print("Starte Gesichtserkennung. Drücken Sie Strg+C zum Beenden.")
        if CAMERA_DEBUG:
            cv2.namedWindow("Gesichtserkennung Debug", cv2.WINDOW_AUTOSIZE)
            print("Debug-Fenster geöffnet. Drücken Sie 'q' im Fenster, um zu beenden.")

        # Hauptschleife für die Frame-Erfassung
        try:
            while True:
                # Frame erfassen
                frame = picam2.capture_array() # Gibt direkt ein NumPy-Array zurück

                # Skaliere den Frame für schnellere Verarbeitung der Gesichtserkennung
                small_frame = cv2.resize(frame, (0, 0), fx=FRAME_RESIZE_FACTOR, fy=FRAME_RESIZE_FACTOR)
                
                face_locations = face_recognition.face_locations(small_frame, model="hog")
                face_encodings = face_recognition.face_encodings(small_frame, face_locations)

                if len(face_locations) > 0:
                    print(f"Gesicht(er) im Videostream erkannt ({len(face_locations)}).")
                
                current_frame_recognized_and_live = False

                display_frame = frame.copy() if CAMERA_DEBUG else None

                # Lese die Konfigurationsdatei für erlaubte Nutzer in jedem Frame
                allowed_users_status = read_allowed_users_config()

                for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
                    top = int(top / FRAME_RESIZE_FACTOR)
                    right = int(right / FRAME_RESIZE_FACTOR)
                    bottom = int(bottom / FRAME_RESIZE_FACTOR)
                    left = int(left / FRAME_RESIZE_FACTOR)

                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.6)
                    name = "Unbekannt"
                    
                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
                    best_match_index = np.argmin(face_distances)

                    liveness_status_text = "Static" # Für Debug-Anzeige
                    access_granted = False # Flag für den tatsächlichen Zugang

                    if matches[best_match_index]:
                        name = known_face_names[best_match_index]
                        
                        # Überprüfe den Status in der Konfigurationsdatei
                        is_allowed_in_config = allowed_users_status.get(name, 'falsch') == 'wahr'

                        # --- Liveness Detection ---
                        current_face_roi = frame[top:bottom, left:right]
                        
                        if current_face_roi.size > 0:
                            if last_face_frame_data is not None and last_face_frame_data.shape == current_face_roi.shape:
                                diff = cv2.absdiff(last_face_frame_data, current_face_roi)
                                sad = np.sum(diff)
                                
                                if sad > LIVENESS_PIXEL_DIFF_THRESHOLD:
                                    liveness_counter += 1
                                    liveness_status_text = "Live?"
                                else:
                                    liveness_counter = 0 
                            else:
                                liveness_counter = 0 
                            
                            last_face_frame_data = current_face_roi.copy() 

                            if liveness_counter >= LIVENESS_CONFIRM_COUNT:
                                liveness_status_text = "LIVE"
                                
                                # Relais-Schaltung nur, wenn auch in Konfigurationsdatei erlaubt
                                if is_allowed_in_config:
                                    if (time.time() - last_recognition_time) > MIN_DETECTION_INTERVAL:
                                        print(f"*** Person erkannt: {name}. Liveness bestätigt! Zugang erlaubt. Relais wird aktiviert. ***")
                                        GPIO.output(RELAY_PIN, GPIO.HIGH) 
                                        time.sleep(RELAY_ACTIVATION_TIME) 
                                        GPIO.output(RELAY_PIN, GPIO.LOW) 
                                        print(f"Relais {RELAY_PIN} deaktiviert.")
                                        
                                        liveness_counter = 0
                                        last_face_frame_data = None
                                        last_recognition_time = time.time() 
                                        current_frame_recognized_and_live = True 
                                        access_granted = True 
                                        
                                        if CAMERA_DEBUG:
                                            cv2.rectangle(display_frame, (left, top), (right, bottom), (0, 255, 0), 2) 
                                            y_text = top - 15 if top - 15 > 15 else top + 15
                                            cv2.putText(display_frame, f"{name} (LIVE) [ZUGANG]", (left + 6, y_text), cv2.FONT_HERSHEY_DUPLEX, 0.6, (0, 255, 0), 1)
                                            cv2.imshow("Gesichtserkennung Debug", display_frame)
                                            cv2.waitKey(100) 
                                        
                                        time.sleep(MIN_DETECTION_INTERVAL) 
                                        break 
                                    else:
                                        access_granted = False 
                                else:
                                    access_granted = False 
                            else:
                                access_granted = False
                        else:
                            liveness_counter = 0
                            last_face_frame_data = None
                            access_granted = False
                    else:
                        liveness_counter = 0 
                        last_face_frame_data = None
                        access_granted = False
                    
                    if CAMERA_DEBUG:
                        color = (0, 0, 255) # Standard: Rot (Unbekannt/Verwehrt)
                        status_text = "Unbekannt"

                        if name != "Unbekannt":
                            if is_allowed_in_config:
                                if liveness_status_text == "LIVE":
                                    if access_granted: 
                                        color = (0, 255, 0) # Grün
                                        status_text = "ZUGANG!"
                                    else: 
                                        color = (255, 165, 0) # Orange
                                        status_text = f"Bekannt ({liveness_status_text})"
                                else: 
                                    color = (255, 0, 0) # Blau
                                    status_text = f"Bekannt ({liveness_status_text})"
                            else: 
                                color = (0, 0, 255) # Rot
                                status_text = "Verwehrt (Config)"
                        else:
                            color = (0, 0, 255) # Rot
                            status_text = "Unbekannt"

                        cv2.rectangle(display_frame, (left, top), (right, bottom), color, 2)
                        y_text = top - 15 if top - 15 > 15 else top + 15
                        cv2.putText(display_frame, f"{name} [{status_text}]", (left + 6, y_text), cv2.FONT_HERSHEY_DUPLEX, 0.6, color, 1)
                
                if not current_frame_recognized_and_live and not face_locations:
                    liveness_counter = 0
                    last_face_frame_data = None

                if CAMERA_DEBUG:
                    cv2.imshow("Gesichtserkennung Debug", display_frame)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("Debug-Fenster geschlossen.")
                        break 

        except KeyboardInterrupt:
            print("\nProgramm beendet durch Benutzer (Strg+C).")
        except Exception as e:
            print(f"Ein unerwarteter Fehler im Kamerastream ist aufgetreten: {e}")
        finally:
            picam2.stop()
            if CAMERA_DEBUG:
                cv2.destroyAllWindows() 

    except Exception as e:
        print(f"Ein unerwarteter Fehler im Hauptprogramm ist aufgetreten: {e}")

if __name__ == "__main__":
    run_face_recognition_system()